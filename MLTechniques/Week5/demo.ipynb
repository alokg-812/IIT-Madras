{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d399a414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt # Already imported\n",
    "\n",
    "from keras.datasets import boston_housing\n",
    "Train, test = boston_housing.load_data(seed= 111)\n",
    "Training_data, labels = Train[0], Train[1]\n",
    "Test_data, test_labels = test[0], test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3865d479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n"
     ]
    }
   ],
   "source": [
    "## Question 1\n",
    "## Enter your solution here\n",
    "print(Training_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6614e353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "## Question 2\n",
    "## Enter your solution here\n",
    "print(Test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfe59a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "## Question 3\n",
    "## Enter your solution here\n",
    "print(Training_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552567ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task: Add the dummy feature\n",
    "## Enter your solution here\n",
    "\n",
    "# Get the number of training and test samples\n",
    "n_train = Training_data.shape[0]\n",
    "n_test = Test_data.shape[0]\n",
    "\n",
    "# Add a column of ones (the dummy feature) to the training data\n",
    "# The resulting shape will be (n, d+1)\n",
    "Training_data_with_bias = np.column_stack((np.ones(n_train), Training_data))\n",
    "\n",
    "# Add a column of ones (the dummy feature) to the test data\n",
    "Test_data_with_bias = np.column_stack((np.ones(n_test), Test_data))\n",
    "\n",
    "# Also reshape labels to (n, 1) vector for consistent matrix operations\n",
    "y_train = labels.reshape(-1, 1)\n",
    "y_test = test_labels.reshape(-1, 1)\n",
    "\n",
    "# Store the final design matrices for convenience:\n",
    "X_train = Training_data_with_bias\n",
    "X_test = Test_data_with_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "173a11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculation for Q4, Q5, Q6, Q7 (Normal Equation Solution)\n",
    "\n",
    "# 1. Calculate X_train^T * X_train\n",
    "XTX = X_train.T @ X_train\n",
    "\n",
    "# 2. Calculate (X_train^T * X_train)^-1\n",
    "XTX_inv = np.linalg.inv(XTX)\n",
    "\n",
    "# 3. Calculate X_train^T * y_train\n",
    "XTy = X_train.T @ y_train\n",
    "\n",
    "# 4. Calculate optimal weights w*\n",
    "w_star = XTX_inv @ XTy\n",
    "\n",
    "# Calculate predictions for training and test sets\n",
    "y_hat_train = X_train @ w_star\n",
    "y_hat_test = X_test @ w_star\n",
    "\n",
    "# Define the Loss function (RMSE)\n",
    "def rmse_loss(y_true, y_pred):\n",
    "    n = y_true.shape[0]\n",
    "    # Sum of squared errors (SSE)\n",
    "    sse = np.sum((y_true - y_pred)**2)\n",
    "    # Mean squared error (MSE)\n",
    "    mse = sse / n\n",
    "    # Root mean squared error (RMSE)\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "913b35b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.524582464661734\n"
     ]
    }
   ],
   "source": [
    "## Question 4\n",
    "## Enter your solution here\n",
    "# Sum of all weights in w*\n",
    "sum_of_w_star = np.sum(w_star)\n",
    "print(sum_of_w_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cde4da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.309158415840525\n"
     ]
    }
   ],
   "source": [
    "avg_predictions = np.mean(y_hat_train)\n",
    "print(avg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af027917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.552387969840813\n"
     ]
    }
   ],
   "source": [
    "## Question 6\n",
    "## Find the loss for the training data points using the above model (Normal Equation solution).\n",
    "# Uses w_star and y_hat_train calculated in the setup for Q4-Q7\n",
    "train_rmse_normal_eq = rmse_loss(y_train, y_hat_train)\n",
    "print(train_rmse_normal_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6848cf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.327662216181203\n"
     ]
    }
   ],
   "source": [
    "## Question 7\n",
    "## Find the loss for the test data points using the above model (Normal Equation solution).\n",
    "# Uses w_star and y_hat_test calculated in the setup for Q4-Q7\n",
    "test_rmse_normal_eq = rmse_loss(y_test, y_hat_test)\n",
    "print(test_rmse_normal_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1e31cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculation for Q8, Q9, Q10 (Gradient Descent)\n",
    "\n",
    "# Assuming previous variables: X_train, y_train, n_train\n",
    "eta = 1e-10  # Learning rate\n",
    "iterations = 100\n",
    "d_plus_1 = X_train.shape[1] \n",
    "\n",
    "# Initialize weights as zero vector\n",
    "w_gd = np.zeros((d_plus_1, 1))\n",
    "\n",
    "# Gradient Descent Loop\n",
    "for i in range(iterations):\n",
    "    # 1. Calculate predictions (y_hat)\n",
    "    y_hat = X_train @ w_gd\n",
    "    \n",
    "    # 2. Calculate the residual (error)\n",
    "    residual = y_hat - y_train\n",
    "    \n",
    "    # 3. Calculate the gradient: (1/n) * X^T * residual\n",
    "    gradient = (1 / n_train) * (X_train.T @ residual)\n",
    "    \n",
    "    # 4. Update the weights\n",
    "    w_gd = w_gd - eta * gradient\n",
    "    \n",
    "# Predictions using the final weights\n",
    "y_hat_train_gd = X_train @ w_gd\n",
    "y_hat_test_gd = X_test @ w_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2121800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00019673280976900844\n"
     ]
    }
   ],
   "source": [
    "## Question 8\n",
    "## Enter your solution here\n",
    "sum_of_w_gd = np.sum(w_gd)\n",
    "print(sum_of_w_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bb77a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.10340179696994\n"
     ]
    }
   ],
   "source": [
    "## Question 9\n",
    "## Enter your solution here\n",
    "train_rmse_gd = rmse_loss(y_train, y_hat_train_gd)\n",
    "print(train_rmse_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3341a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.94764717417876\n"
     ]
    }
   ],
   "source": [
    "## Question 10\n",
    "## Enter your solution here\n",
    "test_rmse_gd = rmse_loss(y_test, y_hat_test_gd)\n",
    "print(test_rmse_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f5dbc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculation for Q11, Q12, Q13 (Stochastic Gradient Descent / Mini-Batch)\n",
    "\n",
    "# Assuming previous variables: X_train, y_train, n_train, X_test\n",
    "eta_sgd = 1e-8  # Learning rate\n",
    "iterations_sgd = 1000\n",
    "d_plus_1 = X_train.shape[1] \n",
    "\n",
    "# Calculate batch size: ceil(n_train / 5)\n",
    "batch_size = int(np.ceil(n_train / 5)) # n_train/5 = 404/5 = 80.8 -> batch_size = 81\n",
    "\n",
    "# Initialize weights as zero vector\n",
    "w_sgd = np.zeros((d_plus_1, 1))\n",
    "\n",
    "# SGD Loop\n",
    "for i in range(1, iterations_sgd + 1):\n",
    "    # Set seed for random sampling (seed at i)\n",
    "    np.random.seed(i)\n",
    "    \n",
    "    # Randomly sample 'batch_size' indices\n",
    "    batch_indices = np.random.choice(n_train, batch_size, replace=False)\n",
    "    \n",
    "    # Create the mini-batch\n",
    "    X_batch = X_train[batch_indices, :]\n",
    "    y_batch = y_train[batch_indices, :]\n",
    "    \n",
    "    # 1. Calculate predictions (y_hat) on the batch\n",
    "    y_hat_batch = X_batch @ w_sgd\n",
    "    \n",
    "    # 2. Calculate the residual (error) on the batch\n",
    "    residual_batch = y_hat_batch - y_batch\n",
    "    \n",
    "    # 3. Calculate the gradient: (1/batch_size) * X_batch^T * residual_batch\n",
    "    gradient_sgd = (1 / batch_size) * (X_batch.T @ residual_batch)\n",
    "    \n",
    "    # 4. Update the weights\n",
    "    w_sgd = w_sgd - eta_sgd * gradient_sgd\n",
    "    \n",
    "# Final weights after 1000 iterations are in w_sgd\n",
    "# Predictions using the final weights\n",
    "y_hat_train_sgd = X_train @ w_sgd\n",
    "y_hat_test_sgd = X_test @ w_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38d46c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.061334305432517444\n"
     ]
    }
   ],
   "source": [
    "## Question 11\n",
    "## Enter the sum of all the weights (w_sgd)\n",
    "sum_of_w_sgd = np.sum(w_sgd)\n",
    "print(sum_of_w_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa2d42e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.899808528977173\n"
     ]
    }
   ],
   "source": [
    "## Question 12\n",
    "## Enter your solution here\n",
    "train_rmse_sgd = rmse_loss(y_train, y_hat_train_sgd)\n",
    "print(train_rmse_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e5abb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.663599407070361\n"
     ]
    }
   ],
   "source": [
    "## Question 13\n",
    "## Enter your solution here\n",
    "test_rmse_sgd = rmse_loss(y_test, y_hat_test_sgd)\n",
    "print(test_rmse_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d575ab7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# X has shape (n, 1), y has shape (n, 1)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mX\u001b[49m, y, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m) \n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScatter Plot of Feature vs. Label\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature (X)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "## Question 14\n",
    "## Plot the scatter plot between feature and the labels. Enter your answer as 0.\n",
    "plt.figure(figsize=(8, 5))\n",
    "# X has shape (n, 1), y has shape (n, 1)\n",
    "plt.scatter(X, y, s=5) \n",
    "plt.title('Scatter Plot of Feature vs. Label')\n",
    "plt.xlabel('Feature (X)')\n",
    "plt.ylabel('Label (y)')\n",
    "plt.show()\n",
    "\n",
    "# Enter your answer as 0\n",
    "print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14a18aa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Question 15\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m## How many examples are there in the training dataset?\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mX\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "## Question 15\n",
    "## How many examples are there in the training dataset?\n",
    "print(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d570a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8012db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed90ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9598ab7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9619120d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394afd21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007c2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e1410f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
